{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ea8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fe55a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['melb_data.csv.zip',\n",
       " '.DS_Store',\n",
       " 'test.csv',\n",
       " 'melb_data.csv',\n",
       " 'data_description.txt',\n",
       " 'test (1).csv',\n",
       " 'train (1).csv',\n",
       " 'train.csv',\n",
       " 'sample_submission.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/paulbolton/Library/CloudStorage/OneDrive-AmplifiGroupLimited/04_Learnings/02_Personal_Projects/03_Kaggle/Kaggle_learnings/Intro to Machine Learning/Data/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f14ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(path+'test.csv')\n",
    "df_train = pd.read_csv(path+'train.csv')\n",
    "df_melbourne_data = pd.read_csv(path+'melb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b912001f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ccd41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13580.000000</td>\n",
       "      <td>1.358000e+04</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13518.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>7130.000000</td>\n",
       "      <td>8205.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "      <td>13580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.937997</td>\n",
       "      <td>1.075684e+06</td>\n",
       "      <td>10.137776</td>\n",
       "      <td>3105.301915</td>\n",
       "      <td>2.914728</td>\n",
       "      <td>1.534242</td>\n",
       "      <td>1.610075</td>\n",
       "      <td>558.416127</td>\n",
       "      <td>151.967650</td>\n",
       "      <td>1964.684217</td>\n",
       "      <td>-37.809203</td>\n",
       "      <td>144.995216</td>\n",
       "      <td>7454.417378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.955748</td>\n",
       "      <td>6.393107e+05</td>\n",
       "      <td>5.868725</td>\n",
       "      <td>90.676964</td>\n",
       "      <td>0.965921</td>\n",
       "      <td>0.691712</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>3990.669241</td>\n",
       "      <td>541.014538</td>\n",
       "      <td>37.273762</td>\n",
       "      <td>0.079260</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>4378.581772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "      <td>249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.500000e+05</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>3044.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>-37.856822</td>\n",
       "      <td>144.929600</td>\n",
       "      <td>4380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.030000e+05</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>3084.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>-37.802355</td>\n",
       "      <td>145.000100</td>\n",
       "      <td>6555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.330000e+06</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058305</td>\n",
       "      <td>10331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000e+06</td>\n",
       "      <td>48.100000</td>\n",
       "      <td>3977.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>433014.000000</td>\n",
       "      <td>44515.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "      <td>21650.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rooms         Price      Distance      Postcode      Bedroom2  \\\n",
       "count  13580.000000  1.358000e+04  13580.000000  13580.000000  13580.000000   \n",
       "mean       2.937997  1.075684e+06     10.137776   3105.301915      2.914728   \n",
       "std        0.955748  6.393107e+05      5.868725     90.676964      0.965921   \n",
       "min        1.000000  8.500000e+04      0.000000   3000.000000      0.000000   \n",
       "25%        2.000000  6.500000e+05      6.100000   3044.000000      2.000000   \n",
       "50%        3.000000  9.030000e+05      9.200000   3084.000000      3.000000   \n",
       "75%        3.000000  1.330000e+06     13.000000   3148.000000      3.000000   \n",
       "max       10.000000  9.000000e+06     48.100000   3977.000000     20.000000   \n",
       "\n",
       "           Bathroom           Car       Landsize  BuildingArea    YearBuilt  \\\n",
       "count  13580.000000  13518.000000   13580.000000   7130.000000  8205.000000   \n",
       "mean       1.534242      1.610075     558.416127    151.967650  1964.684217   \n",
       "std        0.691712      0.962634    3990.669241    541.014538    37.273762   \n",
       "min        0.000000      0.000000       0.000000      0.000000  1196.000000   \n",
       "25%        1.000000      1.000000     177.000000     93.000000  1940.000000   \n",
       "50%        1.000000      2.000000     440.000000    126.000000  1970.000000   \n",
       "75%        2.000000      2.000000     651.000000    174.000000  1999.000000   \n",
       "max        8.000000     10.000000  433014.000000  44515.000000  2018.000000   \n",
       "\n",
       "          Lattitude    Longtitude  Propertycount  \n",
       "count  13580.000000  13580.000000   13580.000000  \n",
       "mean     -37.809203    144.995216    7454.417378  \n",
       "std        0.079260      0.103916    4378.581772  \n",
       "min      -38.182550    144.431810     249.000000  \n",
       "25%      -37.856822    144.929600    4380.000000  \n",
       "50%      -37.802355    145.000100    6555.000000  \n",
       "75%      -37.756400    145.058305   10331.000000  \n",
       "max      -37.408530    145.526350   21650.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melbourne_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5791e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_desc = df_train.describe().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0835617",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'MSSubClass',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold',\n",
       " 'SalePrice']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_train_desc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bbb427e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean    10517.0\n",
       "Name: LotArea, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the average lot size (rounded to nearest integer)?\n",
    "df_train_desc['LotArea'].loc[df_train_desc.index == 'mean'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb7464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max    14.0\n",
       "Name: YearBuilt, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As of today, how old is the newest home (current year - the date in which it was built)\n",
    "2024 - df_train_desc['YearBuilt'].loc[df_train_desc.index == 'max'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d184ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_melbourne_data.columns.tolist()\n",
    "df_melbourne_data = df_melbourne_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf817594",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_melbourne_data.Price\n",
    "features = ['Rooms','Bathroom','Landsize','Lattitude','Longtitude']\n",
    "X = df_melbourne_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1e0b4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "      <td>6196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.931407</td>\n",
       "      <td>1.576340</td>\n",
       "      <td>471.006940</td>\n",
       "      <td>-37.807904</td>\n",
       "      <td>144.990201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.971079</td>\n",
       "      <td>0.711362</td>\n",
       "      <td>897.449881</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.099165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.164920</td>\n",
       "      <td>144.542370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>-37.855438</td>\n",
       "      <td>144.926198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>-37.802250</td>\n",
       "      <td>144.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>628.000000</td>\n",
       "      <td>-37.758200</td>\n",
       "      <td>145.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37000.000000</td>\n",
       "      <td>-37.457090</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Rooms     Bathroom      Landsize    Lattitude   Longtitude\n",
       "count  6196.000000  6196.000000   6196.000000  6196.000000  6196.000000\n",
       "mean      2.931407     1.576340    471.006940   -37.807904   144.990201\n",
       "std       0.971079     0.711362    897.449881     0.075850     0.099165\n",
       "min       1.000000     1.000000      0.000000   -38.164920   144.542370\n",
       "25%       2.000000     1.000000    152.000000   -37.855438   144.926198\n",
       "50%       3.000000     1.000000    373.000000   -37.802250   144.995800\n",
       "75%       4.000000     2.000000    628.000000   -37.758200   145.052700\n",
       "max       8.000000     8.000000  37000.000000   -37.457090   145.526350"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7641f5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-37.8024</td>\n",
       "      <td>144.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-37.8060</td>\n",
       "      <td>144.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms  Bathroom  Landsize  Lattitude  Longtitude\n",
       "1      2       1.0     156.0   -37.8079    144.9934\n",
       "2      3       2.0     134.0   -37.8093    144.9944\n",
       "4      4       1.0     120.0   -37.8072    144.9941\n",
       "6      3       2.0     245.0   -37.8024    144.9993\n",
       "7      2       1.0     256.0   -37.8060    144.9954"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e116edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "melbourne_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7452074a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-37.80790</td>\n",
       "      <td>144.99340</td>\n",
       "      <td>1035000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-37.80930</td>\n",
       "      <td>144.99440</td>\n",
       "      <td>1465000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-37.80720</td>\n",
       "      <td>144.99410</td>\n",
       "      <td>1600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-37.80240</td>\n",
       "      <td>144.99930</td>\n",
       "      <td>1876000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-37.80600</td>\n",
       "      <td>144.99540</td>\n",
       "      <td>1636000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12205</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>-37.51232</td>\n",
       "      <td>145.13282</td>\n",
       "      <td>601000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12206</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>-37.86558</td>\n",
       "      <td>144.90474</td>\n",
       "      <td>1050000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12207</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85588</td>\n",
       "      <td>144.89936</td>\n",
       "      <td>385000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12209</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85581</td>\n",
       "      <td>144.99025</td>\n",
       "      <td>560000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12212</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>-37.81038</td>\n",
       "      <td>144.89389</td>\n",
       "      <td>2450000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6196 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms  Bathroom  Landsize  Lattitude  Longtitude      Price\n",
       "1          2       1.0     156.0  -37.80790   144.99340  1035000.0\n",
       "2          3       2.0     134.0  -37.80930   144.99440  1465000.0\n",
       "4          4       1.0     120.0  -37.80720   144.99410  1600000.0\n",
       "6          3       2.0     245.0  -37.80240   144.99930  1876000.0\n",
       "7          2       1.0     256.0  -37.80600   144.99540  1636000.0\n",
       "...      ...       ...       ...        ...         ...        ...\n",
       "12205      3       2.0     972.0  -37.51232   145.13282   601000.0\n",
       "12206      3       1.0     179.0  -37.86558   144.90474  1050000.0\n",
       "12207      1       1.0       0.0  -37.85588   144.89936   385000.0\n",
       "12209      2       1.0       0.0  -37.85581   144.99025   560000.0\n",
       "12212      6       3.0    1087.0  -37.81038   144.89389  2450000.0\n",
       "\n",
       "[6196 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_melbourne_data[['Rooms','Bathroom','Landsize','Lattitude','Longtitude','Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdcf330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_home_prices = melbourne_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a51a131c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115.7467183128902"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y, predicted_home_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a1b9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path+'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f822476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b362b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15dd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train.SalePrice\n",
    "feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = df_train[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41177f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29652.931506849316\n"
     ]
    }
   ],
   "source": [
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd946a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e38bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max leaf nodes: 75  \t\t Mean Absolute Error:  27114\n",
      "Max leaf nodes: 80  \t\t Mean Absolute Error:  27389\n",
      "Max leaf nodes: 85  \t\t Mean Absolute Error:  27536\n",
      "Max leaf nodes: 90  \t\t Mean Absolute Error:  27411\n",
      "Max leaf nodes: 95  \t\t Mean Absolute Error:  27268\n",
      "Max leaf nodes: 100  \t\t Mean Absolute Error:  27282\n",
      "Max leaf nodes: 105  \t\t Mean Absolute Error:  27171\n",
      "Max leaf nodes: 110  \t\t Mean Absolute Error:  27402\n",
      "Max leaf nodes: 115  \t\t Mean Absolute Error:  27507\n",
      "Max leaf nodes: 120  \t\t Mean Absolute Error:  27503\n",
      "Max leaf nodes: 125  \t\t Mean Absolute Error:  27597\n"
     ]
    }
   ],
   "source": [
    "# candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# candidate_max_leaf_nodes = [50,75,100,125,150,175,200,225,250]\n",
    "candidate_max_leaf_nodes = [75,80,85,90,95,100,105,110,115,120,125]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "_\n",
    "for i in candidate_max_leaf_nodes:\n",
    "    my_mae = get_mae(i, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(i, my_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3b3da4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=75, random_state=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=75, random_state=1)\n",
    "final_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92545c1",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c494935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0016d871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22040.650602640035\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestRegressor(max_leaf_nodes=100,random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "predict_y = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "222fd506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21857.15912981083\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "predict_y = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f133ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(X,y)\n",
    "X = df_test[feature_columns]\n",
    "predict_y = forest_model.predict(X)\n",
    "# print(mean_absolute_error(val_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5b4a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122656.58, 156789.  , 182959.  , ..., 151283.01, 127878.  ,\n",
       "       225959.8 ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2b22c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id':df_test.Id,\n",
    " 'SalesPrice':predict_y})\n",
    "output.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8386309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17905.8978630137\n"
     ]
    }
   ],
   "source": [
    "y = df_train.SalePrice\n",
    "feature_columns = ['MSSubClass','LotArea','OverallQual','OverallCond','YearBuilt','YearRemodAdd','1stFlrSF',\n",
    "                   '2ndFlrSF','LowQualFinSF','GrLivArea','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr',\n",
    "                   'TotRmsAbvGrd','Fireplaces','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch',\n",
    "                   'PoolArea','MiscVal','MoSold','YrSold']\n",
    "X = df_train[feature_columns]\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "predict_y = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94799af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7067.169788356164\n"
     ]
    }
   ],
   "source": [
    "forest_model.fit(X, y)\n",
    "predict_y = forest_model.predict(X)\n",
    "print(mean_absolute_error(y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d1e97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test[feature_columns]\n",
    "predict_y = forest_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5901d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id':df_test.Id,\n",
    " 'SalePrice':predict_y})\n",
    "output.to_csv('submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e90a7e",
   "metadata": {},
   "source": [
    "# Intermediate Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9940ad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.read_csv(path+'train.csv',index_col = 'Id')\n",
    "X_test_full = pd.read_csv(path+'test.csv',index_col = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0fd16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain target and predictors\n",
    "y = X_full.SalePrice\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = X_full[features].copy()\n",
    "X_test = X_test_full[features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d43a1954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8713576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>11694</td>\n",
       "      <td>2007</td>\n",
       "      <td>1828</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>6600</td>\n",
       "      <td>1962</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>13360</td>\n",
       "      <td>1921</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>13265</td>\n",
       "      <td>2002</td>\n",
       "      <td>1689</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>13704</td>\n",
       "      <td>2001</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
       "Id                                                                    \n",
       "619    11694       2007      1828         0         2             3   \n",
       "871     6600       1962       894         0         1             2   \n",
       "93     13360       1921       964         0         1             2   \n",
       "818    13265       2002      1689         0         2             3   \n",
       "303    13704       2001      1541         0         2             3   \n",
       "\n",
       "     TotRmsAbvGrd  \n",
       "Id                 \n",
       "619             9  \n",
       "871             5  \n",
       "93              5  \n",
       "818             7  \n",
       "303             6  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a76e72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_3 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)\n",
    "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc567cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 MAE: 24015\n",
      "Model 2 MAE: 23740\n",
      "Model 3 MAE: 23528\n",
      "Model 4 MAE: 23996\n",
      "Model 5 MAE: 23706\n"
     ]
    }
   ],
   "source": [
    "# Function for comparing different models\n",
    "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "for i in range(0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    print(\"Model %d MAE: %d\" % (i+1, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39ceafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "my_model = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0) # Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00a8c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "my_model.fit(X, y)\n",
    "\n",
    "# Generate test predictions\n",
    "preds_test = my_model.predict(X_test)\n",
    "\n",
    "# Save predictions in format used for competition scoring\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a1945",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86e1d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.read_csv(path+'train.csv',index_col = 'Id')\n",
    "X_test_full = pd.read_csv(path+'test.csv',index_col = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38a21b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MSSubClass, MSZoning, LotFrontage, LotArea, Street, Alley, LotShape, LandContour, Utilities, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, OverallQual, OverallCond, YearBuilt, YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, MasVnrArea, ExterQual, ExterCond, Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, Heating, HeatingQC, CentralAir, Electrical, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, KitchenQual, TotRmsAbvGrd, Functional, Fireplaces, FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, GarageCond, PavedDrive, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, PoolQC, Fence, MiscFeature, MiscVal, MoSold, YrSold, SaleType, SaleCondition, SalePrice]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 80 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.loc[X_full.SalePrice.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a5999eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all the values that dont have a saleprice (predictor column)\n",
    "X_full.dropna(axis=0,subset=['SalePrice'],inplace=True)\n",
    "y = X_full.SalePrice\n",
    "# remove SalePrice from the dataframe\n",
    "X_full.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "193cc934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using numerical columns, ie removes all string data types\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "X_test = X_test_full.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c800ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the training data set and splitting it into a training componant and testing componant\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "123fcf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 36)\n",
      "LotFrontage    212\n",
      "MasVnrArea       6\n",
      "GarageYrBlt     58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "missing_val_count_by_column = X_train.isnull().sum() # counts the missing values for all the columns\n",
    "print(missing_val_count_by_column[missing_val_count_by_column>0])# filters out columns that dont have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d564bb",
   "metadata": {},
   "source": [
    "Since there are relatively few missing entries in the data (the column with the greatest percentage of missing values is missing less than 20% of its entries), we can expect that dropping columns is unlikely to yield good results. This is because we'd be throwing away a lot of valuable data, and so imputation will likely perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6f26109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293f73b",
   "metadata": {},
   "source": [
    "## Drop columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d28008ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop columns with missing values):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989867c",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "492c02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_imputer = SimpleImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8ced29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 36)\n",
      "LotFrontage    212\n",
      "MasVnrArea       6\n",
      "GarageYrBlt     58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "missing_val_count_by_column = X_train.isnull().sum() # counts the missing values for all the columns\n",
    "print(missing_val_count_by_column[missing_val_count_by_column>0])# filters out columns that dont have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c02ae8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad01e5b",
   "metadata": {},
   "source": [
    "These methods are used to center/feature scale of a given data. It basically helps to normalize the data within a particular range\n",
    "\n",
    "For this, we use Z-score method.\n",
    "\n",
    "Z = x - μ / σ \n",
    "\n",
    "We do this on the training set of data.\n",
    "\n",
    "1.Fit(): Method calculates the parameters μ and σ and saves them as internal objects.\n",
    "\n",
    "2.Transform(): Method using these calculated parameters apply the transformation to a particular dataset.\n",
    "\n",
    "3.Fit_transform(): joins the fit() and transform() method for transformation of dataset.\n",
    "\n",
    "Code snippet for Feature Scaling/Standardisation(after train_test_split).\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit_transform(X_train)\n",
    "sc.transform(X_test)\n",
    "\n",
    "We apply the same(training set same two parameters μ and σ (values)) parameter transformation on our testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95beea74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Imputation):\n",
      "18062.894611872147\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d8d2e",
   "metadata": {},
   "source": [
    "Given that thre are so few missing values in the dataset, we'd expect imputation to perform better than dropping columns entirely. However, we see that dropping columns performs slightly better! While this can probably partially be attributed to noise in the dataset, another potential explanation is that the imputation method is not a great match to this dataset. That is, maybe instead of filling in the mean value, it makes more sense to set every missing value to a value of 0, to fill in the most frequently encountered value, or to use some other method. For instance, consider the GarageYrBlt column (which indicates the year that the garage was built). It's likely that in some cases, a missing value could indicate a house that does not have a garage. Does it make more sense to fill in the median value along each column in this case? Or could we get better results by filling in the minimum value along each column? It's not quite clear what's best in this case, but perhaps we can rule out some options immediately - for instance, setting missing values in this column to 0 is likely to yield horrible results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff761d",
   "metadata": {},
   "source": [
    "## Generate test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "587c578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = X_full.select_dtypes(exclude=['object'])\n",
    "final_X_valid = X_test_full.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6912c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_imputer = SimpleImputer(strategy='median')# using the most occuring number\n",
    "final_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "final_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "final_X_train.columns = X_train.columns\n",
    "final_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "97470f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Your approach):\n",
      "17791.59899543379\n"
     ]
    }
   ],
   "source": [
    "# Define and fit model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(final_X_train, y_train)\n",
    "\n",
    "# Get validation predictions and MAE\n",
    "preds_valid = model.predict(final_X_valid)\n",
    "print(\"MAE (Your approach):\")\n",
    "print(mean_absolute_error(y_valid, preds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd350d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_test = pd.DataFrame(my_imputer.transform(X_test))\n",
    "final_X_test.columns = X_test.columns\n",
    "preds_test = model.predict(final_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a27a4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e634e5d",
   "metadata": {},
   "source": [
    "### Score for this submission is 16619.08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf03f33",
   "metadata": {},
   "source": [
    "# Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e02bb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.read_csv(path+'train.csv',index_col = 'Id')\n",
    "X_test_full = pd.read_csv(path+'test.csv',index_col = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37eabe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all the values that dont have a saleprice (predictor column)\n",
    "X_full.dropna(axis=0,subset=['SalePrice'],inplace=True)\n",
    "y = X_full.SalePrice\n",
    "# remove SalePrice from the dataframe\n",
    "X_full.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "112cf1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in X_full.columns if X_full[col].isnull().any()] \n",
    "X_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test_full.drop(cols_with_missing, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "576fe969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_full, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1b9cb77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1b266af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lines below: drop columns in training and validation data\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6448c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17837.82570776256"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dataset(drop_X_train, drop_X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa08824",
   "metadata": {},
   "source": [
    "Before jumping into ordinal encoding, we'll investigate the dataset. Specifically, we'll look at the 'Condition2' column. The code cell below prints the unique entries in both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6220a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeddf75",
   "metadata": {},
   "source": [
    "### Step 2: Ordinal encoding\n",
    "#### Part A\n",
    "If you now write code to:\n",
    "\n",
    "fit an ordinal encoder to the training data, and then\n",
    "use it to transform both the training and validation data,\n",
    "you'll get an error. Can you see why this is the case? (You'll need to use the above output to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3314fcf6",
   "metadata": {},
   "source": [
    "Fitting an ordinal encoder to a column in the training data creates a corresponding integer-valued label for each unique value that appears in the training data. In the case that the validation data contains values that don't also appear in the training data, the encoder will throw an error, because these values won't have an integer assigned to them. Notice that the 'Condition2' column in the validation data contains the values 'RRAn' and 'RRNn', but these don't appear in the training data -- thus, if we try to use an ordinal encoder with scikit-learn, the code will throw an error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086779d6",
   "metadata": {},
   "source": [
    "This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue.  For instance, you can write a custom ordinal encoder to deal with new categories.  The simplest approach, however, is to drop the problematic categorical columns.  \n",
    "\n",
    "Run the code cell below to save the problematic columns to a Python list `bad_label_cols`.  Likewise, columns that can be safely ordinal encoded are stored in `good_label_cols`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "412a6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cfc365aa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "{'RH', 'FV', 'C (all)', 'RL', 'RM'}\n",
      "{'RH', 'FV', 'C (all)', 'RL', 'RM'}\n",
      "True\n",
      "Street\n",
      "{'Pave', 'Grvl'}\n",
      "{'Pave', 'Grvl'}\n",
      "True\n",
      "LotShape\n",
      "{'IR3', 'IR2', 'IR1', 'Reg'}\n",
      "{'IR3', 'IR2', 'IR1', 'Reg'}\n",
      "True\n",
      "LandContour\n",
      "{'HLS', 'Bnk', 'Low', 'Lvl'}\n",
      "{'HLS', 'Bnk', 'Low', 'Lvl'}\n",
      "True\n",
      "Utilities\n",
      "{'AllPub'}\n",
      "{'AllPub', 'NoSeWa'}\n",
      "True\n",
      "LotConfig\n",
      "{'Inside', 'FR3', 'CulDSac', 'Corner', 'FR2'}\n",
      "{'Inside', 'FR3', 'CulDSac', 'Corner', 'FR2'}\n",
      "True\n",
      "LandSlope\n",
      "{'Mod', 'Gtl'}\n",
      "{'Sev', 'Mod', 'Gtl'}\n",
      "True\n",
      "Neighborhood\n",
      "{'NPkVill', 'BrDale', 'Veenker', 'SWISU', 'NoRidge', 'NWAmes', 'Crawfor', 'IDOTRR', 'OldTown', 'MeadowV', 'Edwards', 'Mitchel', 'Sawyer', 'NridgHt', 'NAmes', 'Blmngtn', 'StoneBr', 'Somerst', 'Gilbert', 'Timber', 'SawyerW', 'ClearCr', 'CollgCr', 'BrkSide'}\n",
      "{'NPkVill', 'BrDale', 'Veenker', 'SWISU', 'NoRidge', 'NWAmes', 'Crawfor', 'IDOTRR', 'OldTown', 'MeadowV', 'Edwards', 'Mitchel', 'Sawyer', 'NridgHt', 'NAmes', 'Blmngtn', 'StoneBr', 'Somerst', 'Gilbert', 'Timber', 'SawyerW', 'ClearCr', 'CollgCr', 'BrkSide', 'Blueste'}\n",
      "True\n",
      "Condition1\n",
      "{'Norm', 'Feedr', 'PosA', 'PosN', 'Artery', 'RRAe', 'RRNn', 'RRAn'}\n",
      "{'RRNe', 'Norm', 'Feedr', 'PosA', 'PosN', 'Artery', 'RRAe', 'RRNn', 'RRAn'}\n",
      "True\n",
      "Condition2\n",
      "{'Norm', 'Feedr', 'PosN', 'Artery', 'RRNn', 'RRAn'}\n",
      "{'Norm', 'Feedr', 'PosA', 'PosN', 'Artery', 'RRAe'}\n",
      "False\n",
      "BldgType\n",
      "{'2fmCon', 'Duplex', '1Fam', 'Twnhs', 'TwnhsE'}\n",
      "{'2fmCon', 'Duplex', '1Fam', 'Twnhs', 'TwnhsE'}\n",
      "True\n",
      "HouseStyle\n",
      "{'1.5Fin', '2.5Unf', '2.5Fin', 'SFoyer', '2Story', '1.5Unf', '1Story', 'SLvl'}\n",
      "{'1.5Fin', '2.5Unf', '2.5Fin', 'SFoyer', '2Story', '1.5Unf', '1Story', 'SLvl'}\n",
      "True\n",
      "RoofStyle\n",
      "{'Gable', 'Mansard', 'Gambrel', 'Hip', 'Flat'}\n",
      "{'Mansard', 'Gable', 'Shed', 'Gambrel', 'Hip', 'Flat'}\n",
      "True\n",
      "RoofMatl\n",
      "{'Tar&Grv', 'CompShg', 'ClyTile', 'WdShngl'}\n",
      "{'Tar&Grv', 'CompShg', 'Metal', 'Membran', 'WdShake', 'WdShngl', 'Roll'}\n",
      "False\n",
      "Exterior1st\n",
      "{'CemntBd', 'MetalSd', 'Stucco', 'BrkComm', 'Wd Sdng', 'AsbShng', 'HdBoard', 'WdShing', 'BrkFace', 'Plywood', 'VinylSd'}\n",
      "{'CemntBd', 'MetalSd', 'Stucco', 'AsphShn', 'BrkComm', 'ImStucc', 'Wd Sdng', 'CBlock', 'AsbShng', 'HdBoard', 'WdShing', 'BrkFace', 'Plywood', 'VinylSd', 'Stone'}\n",
      "True\n",
      "Exterior2nd\n",
      "{'CmentBd', 'MetalSd', 'Stucco', 'Brk Cmn', 'AsphShn', 'ImStucc', 'Wd Sdng', 'AsbShng', 'HdBoard', 'BrkFace', 'Plywood', 'Wd Shng', 'VinylSd', 'Stone'}\n",
      "{'Other', 'CmentBd', 'MetalSd', 'Brk Cmn', 'AsphShn', 'Stucco', 'ImStucc', 'Wd Sdng', 'Stone', 'CBlock', 'AsbShng', 'HdBoard', 'BrkFace', 'Plywood', 'VinylSd', 'Wd Shng'}\n",
      "True\n",
      "ExterQual\n",
      "{'Fa', 'Gd', 'Ex', 'TA'}\n",
      "{'Fa', 'Gd', 'Ex', 'TA'}\n",
      "True\n",
      "ExterCond\n",
      "{'Fa', 'Gd', 'TA'}\n",
      "{'Ex', 'Fa', 'Gd', 'Po', 'TA'}\n",
      "True\n",
      "Foundation\n",
      "{'Wood', 'CBlock', 'Slab', 'PConc', 'BrkTil'}\n",
      "{'Wood', 'CBlock', 'Slab', 'PConc', 'BrkTil', 'Stone'}\n",
      "True\n",
      "Heating\n",
      "{'GasW', 'GasA', 'Wall'}\n",
      "{'OthW', 'Floor', 'GasW', 'GasA', 'Wall', 'Grav'}\n",
      "True\n",
      "HeatingQC\n",
      "{'Fa', 'Gd', 'Ex', 'TA'}\n",
      "{'Ex', 'Fa', 'Gd', 'Po', 'TA'}\n",
      "True\n",
      "CentralAir\n",
      "{'N', 'Y'}\n",
      "{'N', 'Y'}\n",
      "True\n",
      "KitchenQual\n",
      "{'Fa', 'Gd', 'Ex', 'TA'}\n",
      "{'Fa', 'Gd', 'Ex', 'TA'}\n",
      "True\n",
      "Functional\n",
      "{'Min2', 'Sev', 'Maj1', 'Mod', 'Typ', 'Maj2', 'Min1'}\n",
      "{'Min2', 'Maj1', 'Mod', 'Typ', 'Maj2', 'Min1'}\n",
      "False\n",
      "PavedDrive\n",
      "{'N', 'Y', 'P'}\n",
      "{'N', 'Y', 'P'}\n",
      "True\n",
      "SaleType\n",
      "{'COD', 'New', 'WD', 'ConLD', 'ConLI', 'CWD', 'Oth', 'Con'}\n",
      "{'ConLw', 'COD', 'New', 'WD', 'ConLD', 'ConLI', 'CWD', 'Oth', 'Con'}\n",
      "True\n",
      "SaleCondition\n",
      "{'Family', 'Partial', 'Abnorml', 'AdjLand', 'Alloca', 'Normal'}\n",
      "{'Family', 'Partial', 'Abnorml', 'AdjLand', 'Alloca', 'Normal'}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for col in object_cols: \n",
    "    print(col)\n",
    "    print(set(X_valid[col]))\n",
    "    print(set(X_train[col]))\n",
    "    print(set(X_valid[col]).issubset(set(X_train[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "15bd30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7c03260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Condition2', 'Functional', 'RoofMatl'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(object_cols)- set(good_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e396acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f594de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be ordinal encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['RoofMatl', 'Functional', 'Condition2']\n"
     ]
    }
   ],
   "source": [
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "692eef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0e7c7fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "17098.01649543379\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5f0a453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SaleCondition\n"
     ]
    }
   ],
   "source": [
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5bea8073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[col].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa8b90",
   "metadata": {},
   "source": [
    "So far, you've tried two different approaches to dealing with categorical variables. And, you've seen that encoding categorical data yields better results than removing columns from the dataset.\n",
    "\n",
    "Soon, you'll try one-hot encoding. Before then, there's one additional topic we need to cover. Begin by running the next code cell without changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f04ea533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00452e7a",
   "metadata": {},
   "source": [
    "## Step 3: Investigating cardinality\n",
    "#### Part A\n",
    "The output above shows, for each column with categorical data, the number of unique values in the column. For instance, the 'Street' column in the training data has two unique values: 'Grvl' and 'Pave', corresponding to a gravel road and a paved road, respectively.\n",
    "\n",
    "We refer to the number of unique entries of a categorical variable as the cardinality of that categorical variable. For instance, the 'Street' variable has cardinality 2.\n",
    "\n",
    "Use the output above to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: How many categorical variables in the training data\n",
    "# have cardinality greater than 10?\n",
    "high_cardinality_numcols = 3\n",
    "\n",
    "# Fill in the line below: How many columns are needed to one-hot encode the \n",
    "# 'Neighborhood' variable in the training data?\n",
    "num_cols_neighborhood = 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56774f48",
   "metadata": {},
   "source": [
    "To one-hot encode a variable, we need one column for each unique entry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccaac16",
   "metadata": {},
   "source": [
    "Part B\n",
    "For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset. For this reason, we typically will only one-hot encode columns with relatively low cardinality. Then, high cardinality columns can either be dropped from the dataset, or we can use ordinal encoding.\n",
    "\n",
    "As an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.\n",
    "\n",
    "If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?\n",
    "If we instead replace the column with the ordinal encoding, how many entries are added?\n",
    "Use your answers to fill in the lines below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e59f04b",
   "metadata": {},
   "source": [
    "Hint: To calculate how many entries are added to the dataset through the one-hot encoding, begin by calculating how many entries are needed to encode the categorical variable (by multiplying the number of rows by the number of columns in the one-hot encoding). Then, to obtain how many entries are added to the dataset, subtract the number of entries in the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "39d5034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many entries are added to the dataset by\n",
    "# replacing the column with a one-hot encoding?\n",
    "OH_entries_added = 1e4*100 - 1e4\n",
    "\n",
    "# How many entries are added to the dataset by\n",
    "# replacing the column with an ordinal encoding?\n",
    "label_entries_added = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90f2b3",
   "metadata": {},
   "source": [
    "Next, you'll experiment with one-hot encoding. But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10.\n",
    "\n",
    "Run the code cell below without changes to set low_cardinality_cols to a Python list containing the columns that will be one-hot encoded. Likewise, high_cardinality_cols contains a list of categorical columns that will be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "206c3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Exterior2nd', 'Exterior1st', 'Neighborhood']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b624ed",
   "metadata": {},
   "source": [
    "# Step 4: One-hot encoding\n",
    "Use the next code cell to one-hot encode the data in X_train and X_valid. Set the preprocessed DataFrames to OH_X_train and OH_X_valid, respectively.\n",
    "\n",
    "The full list of categorical columns in the dataset can be found in the Python list object_cols.\n",
    "You should only one-hot encode the categorical columns in low_cardinality_cols. All other categorical columns should be dropped from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a362af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Use as many lines of code as you need!\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# Ensure all columns have string type\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "df9919fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "17525.345719178084\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a8ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538869c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d70d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
